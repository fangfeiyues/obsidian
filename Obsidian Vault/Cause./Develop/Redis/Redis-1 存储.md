
记一次Redis存储之旅

## 1、事件触发

Redis 是一个事件驱动处理器，需处理以下两类事件：
	1、文件事件：Redis服务器通过`套接字`与`客户端`连接，而文件事件就是服务器对套接字操作的抽象
	2、时间事件：Redis服务器中一些操， 如 `serverCron`
### 文件事件

-  **事件流程**

	Redis 基于 `Reactor模式` 开发 `文件事件处理器（ file event handler）`。其核心步骤是
	1.  文件事件处理器使用`I/O多路复用` 来同时监听多个套接字
	2.  根据目前执行的任务为套接字关联不同的事件处理器
	3.  当被监听的套接字准备好执行 accept、read、write、close等操作时，文件事件处理器就会调用相关联的事件处理器来处理这些事件

	![[Redis-1 存储.png]]


-  **Reactor模式**
	``Reactor模式`是一种事件驱动的设计模式，核心是通过 单线程 或者 多线程 的事件循环来处理I/O操作，从而提高应用程序的并发能力和性能。
	
	``Redis 6.0 后 主Reactor 收到事件后，不再在本线程做收发数据的操作，而是将有事件的客户端加入到一个队列中，然后分配给多个IO线程进行处理。这样，主线程可以专注于执行命令和处理数据，而IO线程负责网络读写操作


-  **套接字Socket**

	``套接字是网络通信的基础组件，它为运行在不同主机上的进程之间提供了一个双向的通信通道；文件事件是对套接字操作的抽象，每当一个套接字准备好执行连接应答（accept）、写入、读取、关闭等操作时，就会产生一个文件事件


-  **I/O多路复用程序**
 
	`I/O多路复用程序负责监听多个套接字，并向文件事件分派器传送那些产生了事件的套接字。I/O多路复用将所有事件的套接字都放入一个队列中，该队列就保证有序同步的方式将套接字向分派器传送套接字


- **分派器**
	`接收I/O多路复用程序传来的套接字，并根据套接字产生的事件的类型，调用相应的事件处理器。


- **事件处理器**
	`服务器会为执行不同任务的套接字关联不同的事件处理器，这些处理器是一个个函数，它们定义了某个事件发生时，服务器应该执行的动作

### 时间事件


## 2、持久化？

### RDB
#### RDB 存储
RDB数据是个经过压缩的二进制文件，其保存方式有3种
1.   `手动触发`
	1.  `save`  执行后会阻塞当前服务器，期间不能处理其他命令
	2.  `bgsave` 执行后会派生出一个子进程，然后由子进程负责创建RDB文件，父进程则继续处理命令
2.  `自动触发` 如 `save 900 1` 表示900秒内如果至少有 1个Key 的值变化则保存

优势：
1.  文件紧凑，全量备份，非常适合于进行备份和灾难恢复。但在开启AOF情况下会优先其
2.  fork子进程 不需 主进程 进行任何磁盘IO操作
3.  恢复速度快
#### RDB 快照
快照是 Redis 把数据由6GB内存同步到硬盘的过程，时间会较长。

Q：数据保存同步期间要注意哪些问题？

	写时候影响的机器性能、写期间缓存&磁盘的一致性、写期间数据宕机安全性 ... 

Q：同步期间如何保证数据一致性？

	核心思路是Copy-on-Write，一方面 Redis 主进程会 fork 一个新的快照进程专门来做这个事情，这样保证了Redis服务不会停止对客户端包括写请求在内的任何响应；
	另一方面这段时间发生的数据变化会以副本的方式存放在另一个新的内存区域，待快照操作结束后才会同步到原来的内存区域

![[Redis-1 存储-1.png|500]]


Q：快照期间服务奔溃了，怎么办？

	在没有将数据全部写入到磁盘前，这次快照操作都不算成功。如果出现了服务崩溃的情况，将以上一次完整的RDB快照文件作为恢复内存数据的参考。也就是说，在快照操作过程中不能影响上一次的备份数据。Redis服务会在磁盘上创建一个临时文件进行数据操作，待操作成功后才会用这个临时文件替换掉上一次的备份。

Q：自动快照时间可以1s每次吗？

	如果频繁的执行全量快照，虽然不会阻塞主线程，但也会带来两方面的开销
	1.频繁将全量数据写入磁盘，会给磁盘带来很大压力
	2.bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程

### AOF

持久化的是命令
#### AOF 存储

AOF( Append Only File ) 会有3个步骤，追加到 `aof_buf缓冲区`，再文件写入`write`，再文件同步`sync`
`flushAppendOnlyFile` 命令写入并同步 AOF磁盘文件
1.  `always` 写入aof_buf 并 同步到 AOF文件
2.  `everysec` 先写入在1s后由一个线程单独同步
3.  `no` 先写入但不同步 何时同步由操作系统决定

```操作系统在调用write函数写入文件的时候，操作系统一般会将数据暂存在 `内存缓冲区`，等区间被填满才真正 `写入磁盘`。这样虽然提升了效率但也带来了安全风险 如果计算机停机，内存缓冲区中的数据会丢失。为此，系统提供了fsync、fdatasync 同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保写入数据的安全性

#### AOF 重写

`rewrite` 是对之前的AOF文件重新分析简化生存新的AOF文件，如就可以简化成直接 RPUSH B C D E F
```redis
redis> RPUSH list 'A' 'B'
redis> RPUSH list 'C' 'D'
redis> LPOP list 'A'
redis> RPUSH list 'E' 'F‘
```


Q：重写会阻塞吗？

	Redis 把 AOF重写程序 放到 子进程 bgrewriteaof 执行，这样有两个好处
	1.  子进程进行 AOF重写 期间，服务器进程（父进程）可以 继续处理 命令请求
	2.  子进程带有 服务器进程 数据副本，使用 子进程 而不是 线程，可以在不使用 锁 的情况保证 数据安全
	   在fork进程时，会阻塞主线程的

Q：重写期间有新数据写入怎么办？

	重写过程总结为：“一个拷贝，两处日志”。
	在fork出子进程时的拷贝，以及在重写时，如果有新数据写入，主线程就会将命令记录到两个aof日志内存缓冲区中。而在bgrewriteaof子进程完成会日志文件的重写操作后，会提示主线程已经完成重写操作，主线程会将AOF重写缓冲中的命令追加到新的日志文件后面。
	这时候在高并发的情况下，AOF重写缓冲区积累可能会很大，这样就会造成阻塞，Redis后来通过Linux管道技术让aof重写期间就能同时进行回放，这样aof重写结束后只需回放少量剩余的数据即可


Q：为什么采用 先写内存 再写日志？

	 1、避免额外的检查开销：Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。
	 2、不会阻塞当前的写操作
	但这种方式存在潜在风险：
	 1、如果命令执行完成，写日志之前宕机了，会丢失数据。
	 2、主线程写磁盘压力大，导致写盘慢，阻塞后续操作。


Q：主线程fork出子进程的是如何复制内存数据的？

	fork采用操作系统提供的写时复制（copy on write）机制，就是为了避免一次性拷贝大量内存数据给子进程造成阻塞。fork子进程时，子进程时会拷贝父进程的页表，即虚实映射关系（虚拟内存和物理内存的映射索引表），而不会拷贝物理内存。这个拷贝会消耗大量cpu资源，并且拷贝完成前会阻塞主线程，阻塞时间取决于内存中的数据量，数据量越大，则内存页表越大。拷贝完成后，父子进程使用相同的内存地址空间。


Q：在重写日志整个过程时，主线程有哪些地方会被阻塞？

	1. fork子进程时，需要拷贝虚拟页表，会对主线程阻塞。
	2. 主进程有bigkey写入时，操作系统会创建页面的副本，并拷贝原有的数据，会对主线程阻塞。
	3. 子进程重写日志完成后，主进程追加aof重写缓冲区时可能会对主线程阻塞。


Q：为什么AOF重写不复用原AOF日志？

	两方面原因：
	1. 父子进程写同一个文件会产生竞争问题，影响父进程的性能。
	2. 如果AOF重写过程中失败了，相当于污染了原本的AOF文件，无法做恢复数据使用。


---



## 3、过期策略

Q：Redis 过期键的删除策略有哪些?

	在单机版Redis中，存在两种删除策略：
	 1、惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。
	 2、定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。
	
	在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。
	
	Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题

Q：Redis 内存淘汰算法有哪些?

	Redis共支持八种淘汰策略，分别是noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random 和 allkeys-lfu 策略。
	  怎么理解呢？主要看分三类看：
	- 不淘汰
	    - noeviction （v4.0后默认的）
	- 对设置了过期时间的数据中进行淘汰
	    - 随机：volatile-random
	    - ttl：volatile-ttl
	    - lru：volatile-lru
	    - lfu：volatile-lfu
	- 全部数据进行淘汰
	    - 随机：allkeys-random
	    - lru：allkeys-lru
	    - lfu：allkeys-lfu

Q：说说LRU算法 & LRF算法？

	LRU算法：LRU 算法的全称是 Least Recently Used，按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。
	
	Redis优化的LRU算法实现：
	
	Redis会记录每个数据的最近一次被访问的时间戳。在Redis在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。通过随机读取待删除集合，可以让Redis不用维护一个巨大的链表，也不用操作链表，进而提升性能。
	
	LFU 算法：LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 Redis的LFU算法实现:
	
	当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。
	
	Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这样在访问快速的情况下，如果每次被访问就将访问次数加一，很快某条数据就达到最大值255，可能很多数据都是255，那么退化成LRU算法了。所以Redis为了解决这个问题，实现了一个更优的计数规则，并可以通过配置项，来控制计数器增加的速度


## 4、主从同步