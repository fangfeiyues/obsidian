
多数情况下不需要微调，一般优先使用应用层技术，如RAG

- 什么情况需要微调
  
	1.  必须要有一个 “自己的” 大模型
	2.  沟通方式、语言风格又特别要求，基座模型靠 prompt 控制不稳定，如AI恋爱、AI面试
	3.  基座模型的训练中，缺少大量的垂直数据，无法完成专业任务，如医疗军事
	4.  基座模型有些任务类型没见过，如LLM去做RPA、自动化操作电脑手机完成任务

-  那些真的需要调

	Agent、Few-Shot、RAG等技术无法做到足够效果
	微调数据量级及质量也都可以有所保障
	基座模型提升后，也得升

-  Fine-Tuning 具体方法

	1.  全模型微调，175B参数都要迭代
	2.  冻结部分参数微调，
	3.  轻量化微调
	4.  渐进微调
	5. 多任务微调


1.  应该选择一个多少参数的基座模型
2.  场景包含的知识量级、任务的复杂度
3.  应该微调其中多大比例的参数
4.  应该为此准备多少数据

## 轻量化微调

### Prompt Tuning


### P-Tuning


Prompt Embedding + LSTM / MLP -->

### Prefix-Tuning



### LoRA Low-Rank A