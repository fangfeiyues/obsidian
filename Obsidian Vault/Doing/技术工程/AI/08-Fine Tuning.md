
多数情况下不需要微调，一般优先使用应用层技术，如RAG

- 什么情况需要微调
  
	1.  必须要有一个 “自己的” 大模型
	2.  沟通方式、语言风格又特别要求，基座模型靠 prompt 控制不稳定，如AI恋爱、AI面试
	3.  基座模型的训练中，缺少大量的垂直数据，无法完成专业任务，如医疗军事
	4.  基座模型有些任务类型没见过，如LLM去做RPA、自动化操作电脑手机完成任务

-  那些真的需要调
  
	Agent、Few-Shot、RAG等技术无法做到足够效果
	微调数据量级及质量也都可以有所保障
	基座模型提升后，也得升

-  Fine-Tuning 具体方法

	1.  全模型微调，175B参数都要迭代
	2.  冻结部分参数微调，
	3.  轻量化微调
	4.  渐进微调
	5. 多任务微调

-  Fine-Tuning 注意点

	1.  应该选择一个多少参数的基座模型
	2.  场景包含的知识量级、任务的复杂度
	3.  应该微调其中多大比例的参数
	4.  应该为此准备多少数据

## 轻量化微调

### Prompt Tuning


### P-Tuning


Prompt Embedding + LSTM / MLP -->

### Prefix-Tuning


### LoRA

Low-Rank Adaptation of LLMs 即是LLM的低秩序适应。
其核心思想是在冻结预训练模型权重后，将可训练的「低秩分解矩阵」注入到的Transformer架构的每一层中，从而大大减少了在下游任务上的可训练参数量。

显著降低训练计算和存储成本，适合处理大规模训练模型。

线性代数：二维矩阵相乘

Wq：12289 * 12288（96层）
Wq + A * B 的矩阵（A是12289 * r 的矩阵，B是 r * 12288的矩阵）
r 比较常见的取值是：4、8、16、32，用很小的参数影响很大的参数


![[Pasted image 20250317115111.png|300]]

QLoRA 希望解决显存占用量过大的问题
比如 7B的模型，70亿 * 4个字节 = 280亿字节 / 1024 / 1028 / 1028 = 25G 内存 


好文章

	https://zhuanlan.zhihu.com/p/702629428